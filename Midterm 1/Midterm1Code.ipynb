{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has a total of different faces with approximately 65 lighting scenes for each face (2414 faces\n",
    "in all). The individual images are columns of the matrix X, where each image has been downsampled\n",
    "to 32 × 32 pixels and converted into gray scale with values between 0 and 1. So the matrix is size\n",
    "1024 × 2414. To important the file, use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "results=loadmat('yalefaces.mat')\n",
    "X=results['X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label the faces from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# Define the number of faces and images per face\n",
    "n_faces = 10\n",
    "n_images_per_face = 64\n",
    "\n",
    "labels = np.repeat(np.arange(n_faces), n_images_per_face)\n",
    "labels = labels.T\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Grab the first 10 individual faces from the data set (each face has 64 lighting scenes). So you will have matrix of size 1024 × 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X[:, 0:(n_faces * n_images_per_face)]\n",
    "data = data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) From the 64 faces of each person, randomly pull out 14 faces for a test set and use the remaining 50 faces for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict stores train and test data\n",
    "data_dict = {}\n",
    "\n",
    "size = 14 / 64\n",
    "\n",
    "x = data[(0 * 64):((0 + 1) * 64)]\n",
    "y = labels[(0 * 64):((0 + 1) * 64)]\n",
    "\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(x, y, test_size=size, random_state=42)\n",
    "\n",
    "for i in range(1, n_faces):\n",
    "    x = data[(i * 64):((i + 1) * 64)]\n",
    "    y = labels[(i * 64):((i + 1) * 64)]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=size, random_state=42)\n",
    "    X_train_all = np.concatenate((X_train_all, X_train), 0)\n",
    "    X_test_all = np.concatenate((X_test_all, X_test), 0)\n",
    "    y_train_all = np.concatenate((y_train_all, y_train), 0)\n",
    "    y_test_all = np.concatenate((y_test_all, y_test), 0)\n",
    "    data_dict[i] = (X_train, y_train, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Do a 20-mode PCA analysis of the face images and evaluate the classification accuracy using a linear discrimant analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1024)\n",
      "(500, 20)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce the dimensionality of the data\n",
    "pca = PCA(n_components=20)\n",
    "\n",
    "print(np.shape(X_train_all))\n",
    "X_pca_train = pca.fit_transform(X_train_all)\n",
    "\n",
    "X_pca_test = pca.fit_transform(X_test_all)\n",
    "\n",
    "print(np.shape(X_pca_train))\n",
    "print(np.shape(y_train_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LDA: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Train a linear classifier\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_pca_train, y_train_all)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = lda.predict(X_pca_test)\n",
    "acc = accuracy_score(y_test_all, y_pred)\n",
    "print(f\"Accuracy for LDA: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM: 0.51\n"
     ]
    }
   ],
   "source": [
    "# Train a linear classifier\n",
    "clf = SVC()\n",
    "clf.fit(X_pca_train, y_train_all)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = clf.predict(X_pca_test)\n",
    "acc = accuracy_score(y_test_all, y_pred)\n",
    "print(f\"Accuracy for SVM: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DTC: 0.15\n"
     ]
    }
   ],
   "source": [
    "# Train a linear classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_pca_train, y_train_all)\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = clf.predict(X_pca_test)\n",
    "acc = accuracy_score(y_test_all, y_pred)\n",
    "print(f\"Accuracy for DTC: {acc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "606ea5fefb8038f588ae3410156c43ba21270a40727e8b601381a52acb156272"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}